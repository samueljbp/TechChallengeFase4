{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "!pip install deepface\n",
        "!pip install tqdm\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRVR4aBUDOC5",
        "outputId": "7a64a16a-22e9-47f8-c00b-0c0309f3bdf4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: deepface in /usr/local/lib/python3.10/dist-packages (0.0.93)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (10.2.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.17.1)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (3.5.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (3.0.3)\n",
            "Requirement already satisfied: flask-cors>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (5.0.0)\n",
            "Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.0.0)\n",
            "Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.0.17)\n",
            "Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.7.0)\n",
            "Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (23.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.16.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.10/dist-packages (from mtcnn>=0.1.0->deepface) (4.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2024.8.30)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement openpose (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for openpose\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from deepface import DeepFace\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    video_path = \"/content/Unlocking Facial Recognition_ Diverse Activities Analysis.mp4\"\n",
        "    output_video_path = \"video_tech_challenge_modified.mp4\"\n",
        "    output_summary_path = \"video_summary.txt\"\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    mp_face_detection = mp.solutions.face_detection.FaceDetection(min_detection_confidence=0.5)\n",
        "    mp_pose = mp.solutions.pose.Pose()\n",
        "\n",
        "    activity_summary = []\n",
        "    emotions_summary = []\n",
        "    anomalies_count = 0\n",
        "\n",
        "    with tqdm(total=frame_count, desc=\"Processando vídeo\") as pbar:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Process all frames for emotions\n",
        "            frame, detected_emotions = detect_and_mark_faces_and_emotions(frame, mp_face_detection)\n",
        "            if detected_emotions:\n",
        "                emotions_summary.extend(detected_emotions)\n",
        "\n",
        "            # Process all frames for activities\n",
        "            activity, _ = detect_activity(frame, mp_pose)\n",
        "            if activity:\n",
        "                activity_summary.append(activity)\n",
        "\n",
        "                # Display detected activity on video\n",
        "                cv2.putText(frame, f\"Atividade: {activity}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
        "\n",
        "            # Write processed frame to output\n",
        "            out.write(frame)\n",
        "            pbar.update(1)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Generate activity and emotions summary\n",
        "    generate_summary(activity_summary, emotions_summary, output_summary_path, frame_count, anomalies_count)\n",
        "    print(f\"Vídeo processado e salvo como {output_video_path}\")\n",
        "    print(f\"Resumo salvo em {output_summary_path}\")\n",
        "\n",
        "\n",
        "def detect_and_mark_faces_and_emotions(frame, mp_face_detection):\n",
        "    detected_emotions = []\n",
        "\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = mp_face_detection.process(frame_rgb)\n",
        "\n",
        "    if results.detections:\n",
        "        for detection in results.detections:\n",
        "            bboxC = detection.location_data.relative_bounding_box\n",
        "            h, w, _ = frame.shape\n",
        "            left, top, width, height = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)\n",
        "            right, bottom = left + width, top + height\n",
        "\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "\n",
        "            face_frame = frame[top:bottom, left:right]\n",
        "\n",
        "            try:\n",
        "                result = DeepFace.analyze(face_frame, actions=['emotion'], enforce_detection=False)\n",
        "                if result:\n",
        "                    emotion = result[0]['dominant_emotion']\n",
        "                    detected_emotions.append(emotion)\n",
        "                    cv2.putText(frame, emotion, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "    return frame, detected_emotions\n",
        "\n",
        "\n",
        "def detect_activity(frame, mp_pose):\n",
        "    \"\"\"\n",
        "    Identify posture (standing, sitting, lying) and detect dancing.\n",
        "    \"\"\"\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    pose_results = mp_pose.process(frame_rgb)\n",
        "\n",
        "    if pose_results.pose_landmarks:\n",
        "        landmarks = pose_results.pose_landmarks.landmark\n",
        "        h, w = frame.shape[:2]\n",
        "\n",
        "        # Helper function to get (x, y) coordinates\n",
        "        def get_coords(landmark):\n",
        "            return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "        # Extract relevant landmarks\n",
        "        left_hip = landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP]\n",
        "        right_hip = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP]\n",
        "        left_shoulder = landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER]\n",
        "        right_shoulder = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER]\n",
        "        left_knee = landmarks[mp.solutions.pose.PoseLandmark.LEFT_KNEE]\n",
        "        right_knee = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_KNEE]\n",
        "        left_wrist = landmarks[mp.solutions.pose.PoseLandmark.LEFT_WRIST]\n",
        "        right_wrist = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_WRIST]\n",
        "\n",
        "        # Posture detection\n",
        "        # Calculate angles or distances\n",
        "        hips_y = (left_hip.y + right_hip.y) / 2\n",
        "        shoulders_y = (left_shoulder.y + right_shoulder.y) / 2\n",
        "        knees_y = (left_knee.y + right_knee.y) / 2\n",
        "\n",
        "        if abs(hips_y - shoulders_y) < 0.1:  # Shoulders and hips aligned horizontally\n",
        "            posture = \"Deitada\"\n",
        "        elif abs(hips_y - knees_y) < 0.2:  # Hips and knees close in height\n",
        "            posture = \"Sentada\"\n",
        "        else:\n",
        "            posture = \"Em pe\"\n",
        "\n",
        "        # Dance detection (hand movement above shoulders)\n",
        "        left_hand_up = left_wrist.y < left_shoulder.y\n",
        "        right_hand_up = right_wrist.y < right_shoulder.y\n",
        "\n",
        "        if left_hand_up or right_hand_up:\n",
        "            dancing = \"Dancando\"\n",
        "        else:\n",
        "            dancing = \"Nao dancando\"\n",
        "\n",
        "        # Draw landmarks only when hands are visible\n",
        "        if left_wrist.visibility > 0.5 or right_wrist.visibility > 0.5:\n",
        "            mp.solutions.drawing_utils.draw_landmarks(\n",
        "                frame,\n",
        "                pose_results.pose_landmarks,\n",
        "                mp.solutions.pose.POSE_CONNECTIONS,\n",
        "                mp.solutions.drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
        "                mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)\n",
        "            )\n",
        "\n",
        "        # Combine results\n",
        "        return f\"Postura: {posture}, {dancing}\", None\n",
        "\n",
        "    return \"Nao detectado\", None\n",
        "\n",
        "\n",
        "def generate_summary(activities, emotions, output_path, frame_count, anomalies_count):\n",
        "    activity_counter = Counter(activities)\n",
        "    emotion_counter = Counter(emotions)\n",
        "\n",
        "    with open(output_path, \"w\") as f:\n",
        "        f.write(\"Resumo do vídeo:\\n\\n\")\n",
        "        f.write(f\"Total de frames analisados: {frame_count}\\n\")\n",
        "        f.write(f\"Número de anomalias detectadas: {anomalies_count}\\n\\n\")\n",
        "\n",
        "        f.write(\"Atividades detectadas:\\n\")\n",
        "        for activity, count in activity_counter.items():\n",
        "            f.write(f\"- {activity}: detectado {count} vezes\\n\")\n",
        "\n",
        "        f.write(\"\\nEmoções predominantes:\\n\")\n",
        "        for emotion, count in emotion_counter.items():\n",
        "            f.write(f\"- {emotion}: detectado {count} vezes\\n\")\n",
        "\n",
        "        f.write(\"\\nAnálise geral:\\n\")\n",
        "        if activity_counter:\n",
        "            most_common_activity = activity_counter.most_common(1)[0]\n",
        "            f.write(f\"A atividade mais frequente no vídeo foi '{most_common_activity[0]}', \"\n",
        "                    f\"ocorrendo aproximadamente {most_common_activity[1]} vezes.\\n\")\n",
        "\n",
        "        if emotion_counter:\n",
        "            most_common_emotion = emotion_counter.most_common(1)[0]\n",
        "            f.write(f\"A emoção predominante foi '{most_common_emotion[0]}', \"\n",
        "                    f\"aparecendo em aproximadamente {most_common_emotion[1]} quadros.\\n\")\n",
        "\n",
        "    print(f\"Resumo salvo em {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsz88xB-DFVB",
        "outputId": "201c01cb-a84b-427a-edd7-e6f3467399de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando vídeo: 100%|██████████| 3326/3326 [09:03<00:00,  6.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumo salvo em video_summary.txt\n",
            "Vídeo processado e salvo como video_tech_challenge_modified.mp4\n",
            "Resumo salvo em video_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}